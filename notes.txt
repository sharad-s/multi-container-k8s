docker-compose afaik is used only in practice for development purposes. 

Nginx has to be deployed in front of all containers as a proxy router, as well as packaged inside the Client container 
The Nginx Config is not covered in depth in this course and must be learned separately.

Pushing to dockerhub requires that you tag the image. The image can be tagged with the format "<DOCKERID>/<NICKNAME>" or just "<NICKNAME>".
If you provide an incorrect DOCKERID, the push will fail. If you provide no DOCKERID, your image tag will automatically be prepended with your DOCKERID. 

.travis.yml can be janky. If pushing to Dockerhub via travis, you must login via the CLI. Use Travis's encrypted environment variables to store your Docker credentials. 

Dockerrrun.aws.json is required for multi-container deployments to AWS. It serves the same purpose as docker-compose, except tells AWS how to deploy multiple containers using docker. 

Elastic Container Service (ECS) Task Definitions tell AWS how to run a docker file. We write Container deifnitions.     
 - https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ecs-taskdefinition-containerdefinitions.html


Dockerrun.aws.json  
    - you're basically rewriting docker-compose in AWS's preferred format. 
    - essential flag true means if one container crashes in the array, the other ones would be spun down too.  
     - at least one service usually must be marked essential. for this project it's NginX. 
    - port maps must be an object
    - links property allows for networking between containers. docker-compose took care of it for you but that's not the case with AWS. this property allows that functionality to occur. 
    - the "link" property uses specificially the "name" property of the other containers and does not use the "hostname" property.
    - however container logic like nginx config uses the "hostname" property. this needs more explanation as to why. 
    - Must add "memory" property otherwise deployment will fail. Default starting point is 128


Postgres and Redis?
https://www.udemy.com/docker-and-kubernetes-the-complete-guide/learn/lecture/11437370#questions
 - Redis = AWS Elsatic Cache
 - PG = AWS RDS 
 AWS EC and RDS are Decoupled - you can move the rest of your app elsewhere and still continue to use RDS and EC
 https://blog.hasura.io/instant-graphql-on-aws-rds-1edfb85b5985/
 

Security Groups - 
Connecting EB to RDS and EC requires specialized links created inside AWS. This is called a security group
Lets you create rules to allow AWS services to talk to each other if they're in the same security group
Create security group and allow traffic from any other instance within this security group. Once you create the security group, apply it to all instances of EB, EC, and RDS

ENV Variables
You set EB ENV Variables through the EB settings dashboard 
When you set ENV Variables they get automatically added to every container running inside that EB instance. 
For some reason these are stored plaintext and anyone with access to this account can see them

Travis deploying a multi-container app to EC
- Generate a new user through IAM. Give it programmatic access to .
- Store the Access Key and Secret Key as ENV vars in Travis CI. Travis will use these keys to deploy the application to EB.
- 



Finishing THoughts
 - Beanstalk lets you deploy a containerized app or multi-containerized app and scale it based on need.
 - Dockerizing all your services allows you to push up all your services, EB will just accept it and run it as you define it through Docker. 
    - This is better in comparison to having to set up servers for each service and configure each separately. 
 - In DEV, you run Postgres and Redis in docker containers locally through docker-compose. In PROD - you don't deploy docker containers for these services.
    - Services like Postgres (DB) and Redis (Caching) are offered through AWS services (RDS and ElastiCache). 
    - Utilize ENV variables in your source code so that you can easily connect to whatever service you want in dev/prod later. 
    - Setting ENV vars in the AWS Elastic Beanstalk instance you create lets you swap services for DB/Caching (Postgres and Redis) without touching any source code. 
 - In DEV, docker-compose handles all networking between services. AWS makes use of "security groups" and rules to explicitly define networking between services.
  
 - AWS Notes
  - Instantiate RDS for Postgres, ElastiCache for Redis, and EB as a web-app multi-container Docker instance for the app itself
  - Set up the VPC Security Group, add rule to allow communication between services in gropu. Attach Security group to all 3 things. 
  - Write Dockerrun.aws.json in your app. It's like docker-compose for AWS. 
  - Create new IAM user to access Elastic Beanstalk. Copy User API Keys to Travis for deployment. 
  - Set ENV Variables for EB. Your Postgres and Redis instance will have hostnames generated for you by AWS.
    These need to be set in ElasticBeanstalk to facilitate comms by your app to those instances
     - Then deployment should work 



 Bugs encountered:
  - I couldn't push my docker images from the Travis pipeline even though I was logged in to Docker in the Travis pipeline.
    Because I miswrote my dockerID for my docker images in the travis.yml file. 
    My DockerID is "sharadshekar", but I wrote "sharad-s" (my github id). 
    this was because sharadshekar was not able to push an image tagged as "sharad-s/multi-docker" because he was not "sharad-s". 
    changing the image tag to "sharadshekar/multi-docker" fixed this issue

  - I couldnt succesfully deploy my app to Beanstalk 
    Because I forgot to set a service as "essential" in Dockerrun.aws.json.
    My error string was "Service:AmazonECS, Code:ClientException, Message:Task definition doesn't have any essential container ..."
    I set nginx service to "essential:true" in Dockerrun.aws.json




K8S K8s K8s

## ClusterIP Service?

 - What is clusterIP 
 
